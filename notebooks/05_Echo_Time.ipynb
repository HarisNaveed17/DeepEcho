{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Handling DateTime Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is 1594536602?\n",
    "Let's start with the (overly optimistic) assumption that all datetime value are represented as Unix time.\n",
    "\n",
    "*Note: This assumption fails when we have to take into account things like how the value should be presented (i.e. time zones, 1997-12-12 vs 12/12/1996, etc.).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now suppose we have the following dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\"datetime\": 1577836800, \"nb_customers\": 1},\n",
    "    {\"datetime\": 1578182400, \"nb_customers\": 10},\n",
    "    {\"datetime\": 1578441600, \"nb_customers\": 2},\n",
    "    {\"datetime\": 1578787200, \"nb_customers\": 8}\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we were trying to apply standard machine learning algorithms to, for example, predict the number of customers on a given day, our path forward would be simple. We would use some feature engineering methods to transform the datetime into more easily interpretable features for the model.\n",
    "\n",
    "For example, in this case, if we added a `day_of_week` feature, then our model would easily learn that there are more customers on Sundays than Wednesdays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generating Timestamps\n",
    "Feature extraction is a powerful tool for discriminative models... but it's not clear how to translate those ideas into a generative framework such as **DeepEcho**.\n",
    "\n",
    "> *In fact, to the best of my knowledge, there exist no papers in the space of synthetic data generation, generative adversarial networks, autoregressive models, etc. which discuss how to generate timestamps.*\n",
    "\n",
    "The default way to handle time stamp values appears to be involve simply normalizing the Unix timestamp into a value in $[-1.0, 1.0]$ based on the minimum and maximum timestamp in the data and treating it as a real number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Modeling Distributions\n",
    "Within **DeepEcho**, our models tend to generate as outputs distributions over data (as opposed to producing the actual synthetic data). This is important as it allows us to separate the sampling stage from the modeling stage, particularly in the case of autoregressive models which would otherwise be deterministic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Continuous Values\n",
    "For example, in the `PARModel`, when modeling continuous values, our model outputs three values:\n",
    "\n",
    " - `mu` - the mean of the Normal distribution\n",
    " - `var` - the variance of the Normal distribution\n",
    " - `missing` - the probability that the value is misisng\n",
    "\n",
    "which we can use to generate a value by (1) sampling whether the value is missing and (2) if the value is not missing, sampling from the Normal distribution with the given mean and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Timestamps as Continuous Values\n",
    "This works well for a wide variety of continuous-valued variables. However, it has some clear weaknesses if you try to use it to handle Unix timestamps.\n",
    "\n",
    "For example, suppose your dataset only contains Sundays at 12am. The model would have to learn that the timestamps it generates should satisfy `x mod 259200 = 0`. Normalizing your timestamps to `[-1.0, 1.0]` range doesn't necesssarily help - it might even hurt!\n",
    "\n",
    "Therefore, we're looking for some way to specify a distribution over timestamps that:\n",
    "1. Makes it easy for the model to learn cyclical and seasonal properties\n",
    "2. Has a fixed scale which doesn't require additional/arbitrary normalization\n",
    "3. Can be efficiently sampled from.\n",
    "4. Has a functional form which allows us to log-likelihood of the data and then compute the gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modeling Timestamps\n",
    "The **rejection sampling** framework gives us the tools to sample from an unnormalized probability distribution where (1) we know the range of possible x-values and (2) we know the maximum value of the pdf. Using rejection sampling, we can avoid having to specify a well-formed pdf/cdf at the cost of a little extra computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Motivating Example\n",
    "This allows us to think of our \"distribution\" over timestamps as a scoring function such as:\n",
    "\n",
    "$$\n",
    "    P(\\texttt{timestamp}) \\propto\n",
    "        a \\cdot I[\\texttt{is_winter}] + \n",
    "        b \\cdot I[\\texttt{is_monday}] +\n",
    "        c \\cdot I[\\texttt{is_sunday}]\n",
    "$$\n",
    "\n",
    "where $a$, $b$, and $c$ are the parameters of the distribution and must be in range $[0.0, 1.0]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### As Input\n",
    "When providing a timestamp as input to the model, we simply set the parameters equal to the corresponding indicator variable. For example, if our value is `1578182400`, then we set $a=1.0$ since the date is in the winter, $b=0.0$ since it is not a Monday, and $c=1.0$ since it is a Sunday.\n",
    "\n",
    "Note that in this example scoring function, all Sundays in the winter are equally likely (i.e. they all receive the same score and are therefore equally likely to be sampled)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### As Output\n",
    "When these parameters are produced by the model, they specify a scoring function which takes a timestamp and returns a real-valued score between in the range $[0.0, 3.0]$ which is proportional to the value of the pdf at the given timestamp. Using rejection sampling, we can sample from this pdf and obtain timestamps!\n",
    "\n",
    "For example, suppose our model produces $a=1.0$, $b=1.0$, $c=1.0$. Intuitively, this would suggest that we are more likely to sample a timestamp that is in the winter and on a Monday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementation\n",
    "Here's a quick-and-dirty implementation of the scoring function, rejection sampling, and corresponding transform/sample steps. Don't pay too much attention to this, we can definately do a better job of making it more readible and computationally efficient.\n",
    "\n",
    "**Aside: Why isn't this an RDT?** *Well, the main distinction between this and an RDT is that the \"reverse transform\" involves sampling (and is not deterministic/\"reversible\".) However, if you want to package it as part of RDT, I'm fine with that. This document is intended to describe the mathematical framework for modeling timestamps as opposed to recommending some specific software design / structure.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "class EchoTime():\n",
    "    \n",
    "    def score(self, timestamp, params):\n",
    "        dt = datetime.fromtimestamp(timestamp)\n",
    "        return params[dt.weekday()]\n",
    "    \n",
    "    def to_params(self, timestamp):\n",
    "        params = [0.0] * 7\n",
    "        dt = datetime.fromtimestamp(timestamp)\n",
    "        params[dt.weekday()] = 1.0\n",
    "        return params\n",
    "\n",
    "    def from_params(self, params, max_tries=1000):\n",
    "        for _ in range(max_tries):\n",
    "            timestamp = np.random.randint(1535730073, 1555730073)\n",
    "            u = np.random.uniform(0, 1.0) # max value = 1.0\n",
    "            if u <= self.score(timestamp, params):\n",
    "                return timestamp\n",
    "\n",
    "    def transform(self, df, target_column):\n",
    "        \"\"\"Transform the target datetime column.\n",
    "        \"\"\"\n",
    "        new_df = []\n",
    "        self.columns = df.columns\n",
    "        self.target_column = target_column\n",
    "        for row in df.to_dict('records'):\n",
    "            params = et.to_params(row[target_column])\n",
    "            del row[target_column]\n",
    "            self.dt_columns = []\n",
    "            for i, param in enumerate(params):\n",
    "                row[\"%s.%s\" % (target_column, i)] = param\n",
    "                self.dt_columns.append(\"%s.%s\" % (target_column, i))\n",
    "            new_df.append(row)\n",
    "        return pd.DataFrame(new_df)\n",
    "\n",
    "    def sample(self, df):\n",
    "        new_df = []\n",
    "        for row in df.to_dict('records'):\n",
    "            params = []\n",
    "            for c in self.dt_columns:\n",
    "                params.append(row[c])\n",
    "                del row[c]\n",
    "            row[self.target_column] = self.from_params(params)\n",
    "            new_df.append(row)\n",
    "        return pd.DataFrame(new_df, columns=self.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demo\n",
    "Recall our example dataset from earlier where we discovered that we had more customers on Saturdays than Tuesdays. Let's try to model this dataset using Copulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>nb_customers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1577836800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1578182400</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1578441600</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1578787200</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     datetime  nb_customers\n",
       "0  1577836800             1\n",
       "1  1578182400            10\n",
       "2  1578441600             2\n",
       "3  1578787200             8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, we'll write a simple helper function which summarizes the dataset. We'll use this function to generate a human-readible printout which highlights some of the properties of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_nb_customers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_week</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Saturday</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuesday</th>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             avg_nb_customers\n",
       "day_of_week                  \n",
       "Saturday                  9.0\n",
       "Tuesday                   1.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize(df):\n",
    "    daysOftheWeek = (\n",
    "        \"Monday\",\n",
    "        \"Tuesday\",\n",
    "        \"Wednesday\",\n",
    "        \"Thursday\",\n",
    "        \"Friday\",\n",
    "        \"Saturday\",\n",
    "        \"Sunday\"\n",
    "    )\n",
    "    df = df.copy()\n",
    "    df[\"day_of_week\"] = [daysOftheWeek[datetime.fromtimestamp(x).weekday()] for x in df[\"datetime\"]]\n",
    "    df = df.drop(\"datetime\", axis=1).groupby(\"day_of_week\").agg(\"mean\")\n",
    "    return df.rename({\"nb_customers\": \"avg_nb_customers\"}, axis=1)\n",
    "\n",
    "summarize(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we see that (1) our dataset only contains Tuesdays and Saturdays and (2) on average, there are much more customers on Saturday than Tuesday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Direct Modeling\n",
    "Let's see what happens if we directly pass this data to Copulas. Note that we could also use something RDT to transform the datatime values; however, the current datetime transformer in RDT simply transforms it into Unix time so it's essentially a no-op in this case (since there are no missing values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_nb_customers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_week</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Monday</th>\n",
       "      <td>9.233596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saturday</th>\n",
       "      <td>8.012633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunday</th>\n",
       "      <td>6.315706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wednesday</th>\n",
       "      <td>4.472315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             avg_nb_customers\n",
       "day_of_week                  \n",
       "Monday               9.233596\n",
       "Saturday             8.012633\n",
       "Sunday               6.315706\n",
       "Wednesday            4.472315"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copulas.multivariate import GaussianMultivariate\n",
    "copula = GaussianMultivariate()\n",
    "copula.fit(df)\n",
    "synthetic_df = copula.sample(10)\n",
    "summarize(synthetic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see here, the synthetic data (1) contains timestamps from other days which do not belong and (2) does not capture the property that there are more cusomers on Saturdays than Tuesays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using EchoTime\n",
    "Now let's see what happens if we first transform the column using EchoTime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deepecho/lib/python3.7/site-packages/numpy/core/fromnumeric.py:56: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_nb_customers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_week</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Saturday</th>\n",
       "      <td>9.086956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuesday</th>\n",
       "      <td>1.080311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             avg_nb_customers\n",
       "day_of_week                  \n",
       "Saturday             9.086956\n",
       "Tuesday              1.080311"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copulas.multivariate import GaussianMultivariate\n",
    "\n",
    "et = EchoTime()\n",
    "copula = GaussianMultivariate()\n",
    "copula.fit(et.transform(df, \"datetime\"))\n",
    "synthetic_df = et.sample(copula.sample(10))\n",
    "summarize(synthetic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we are now able to capture both properties! The synthetic dataset only contains Tuesdays and Saturdays and, on average, there are much more customers on Saturday than Tuesday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Takeaways\n",
    "The EchoTime methodology - which consists of defining a distribution over timestamps using a scoring function and applying rejection sampling - is a powerful, flexible, and effective approach to modeling timestamp data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
